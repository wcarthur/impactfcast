{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using wind and rainfall as a discriminator for damage\n",
    "\n",
    "This notebook explores the potential of using rainfall and wind speed data as a discriminator for damage to buildings. \n",
    "\n",
    "The \"forecast\" is the Bureau of Meteorology Atmospheric high-resolution Regional Reanalysis for Australia (BARRA), and uses four different measures of wind speed and rainfall:\n",
    "* Surface wind gust (PSWG)\n",
    "* Surface \"mean\" wind (PSMW)\n",
    "* 900 hPa wind speed (PGWS)\n",
    "* \"Neighbourhood\" surface wind gust (NSWG)\n",
    "* Maximum instantaneous rainfall rate (PIRR)\n",
    "* Maximum 1-hour rainfall rate (P1RR)\n",
    "* Maximum 6-hour rainfall rate (P6RR)\n",
    "* Event total rainfall accumulation (PTEA)\n",
    "* \"Neighbourhood\" 1 -hour rainfall rate (N1RR)\n",
    "\n",
    "These fields are all extracted from 10-minute time step fields (provided by David Wilke). \n",
    "\n",
    "The \"Neighbourhood\" fields apply a spatial filter that takes the highest value within a prescribed radius of each point and assigns it to that point. In this case, the radius has been set at approximately 0.36$^{\\circ}$ (40 km).\n",
    "\n",
    "The codes following each line above are the variable name as used throughout this notebook, and the field names in the input shape file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load the required modules for the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")\n",
    "from matplotlib import colors\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the data paths and read the data into a geoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"X:/georisk/HaRIA_B_Wind/projects/impact_forecasting/data/impact/dungog\"\n",
    "data_path = \"C:/WorkSpace/data/impact\"\n",
    "filename = \"damage_hazard.shp\"\n",
    "filepath = pjoin(data_path, filename)\n",
    "\n",
    "gdf = gpd.read_file(filepath)\n",
    "\n",
    "DMG_ORDER=['No Damage - 0%','Minor Impact - 1-25%', 'Major Impact - 26-50%', 'Severe Impact - 51-75%','Destroyed - 76-100%']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop any records where the hazard variables are null. This removes any records outside the extent of the BARRA-SY grid, but I do not think there are any in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.dropna(axis=0, inplace=True, subset=['PIRR', 'P1RR', 'N1RR', 'P6RR', 'PTEA',\n",
    "                                         'PSWG', 'PSMW', 'NSWG', 'PGWS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first instance, we simply want to model the probability of buildings being damaged or undamaged. To do this, we add a numeric field to represent those buildings that are either classified as \"Major Impact\", \"Severe Impact\" or \"Destroyed\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "damaged = np.zeros(len(gdf))\n",
    "damaged[gdf['EICU_Degda'].isin(['Destroyed - 76-100%', \n",
    "                                 'Severe Impact - 51-75%', \n",
    "                                 'Major Impact - 26-50%', \n",
    "                                 ])] = 1\n",
    "\n",
    "gdf['Damaged'] = damaged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the list of variables representing rainfall and wind speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall = ['PIRR', 'P1RR', 'N1RR', 'P6RR', 'PTEA']\n",
    "wind = ['PSWG', 'PSMW', 'NSWG', 'PGWS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we cycle through the combinations of rainfall and wind variables, and calculate a quadratic discriminant analysis, with these as the predictor variables and the 'Damaged' variable as the predictand. This produces a 5 x 4 plot, with each panel represeting the QDA using a unique combination of rainfall and wind variables. In each, the wind variable is on the horizontal axis and the rainfall variable on the vertical axis. The shading represents the probabilty of being in the \"Damaged\" category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5,4, figsize=(24,20),facecolor='white')\n",
    "ax = axes.flatten()\n",
    "xx = np.linspace(0, 100, 1000)\n",
    "yy = np.linspace(0, 500, 1000)\n",
    "xp, yp = np.meshgrid(xx, yy)\n",
    "for i, (r, w) in enumerate(product(rainfall, wind)):\n",
    "    X = np.array([gdf[w].values, gdf[r].values]).T\n",
    "    y = gdf['Damaged'].values\n",
    "    clf = QDA()\n",
    "    clf.fit(X, y)\n",
    "    Z = clf.predict_proba(np.c_[xp.ravel(), yp.ravel()])\n",
    "    Z = Z[:, 1].reshape(xp.shape)\n",
    "    cm = ax[i].pcolormesh(xp, yp, Z, cmap='viridis', norm=colors.Normalize(0., 1))\n",
    "    cs = ax[i].contour(xp, yp, Z, [0.05, 0.1, 0.25,0.5, 0.75], linewidths=2., colors='k')\n",
    "    ax[i].clabel(cs, fmt='%.2f')\n",
    "    #ax[i].colorbar(cm, label=\"Probability of damage\")\n",
    "    if i>15:\n",
    "        ax[i].set_xlabel(w)\n",
    "    if i%4 == 0:\n",
    "        ax[i].set_ylabel(r)\n",
    "    ax[i].set_xlim((np.floor(gdf[w].values.min()/10)*10, \n",
    "                    np.ceil(gdf[w].values.max()/10)*10))\n",
    "    ax[i].set_ylim((gdf[r].values.min(), gdf[r].values.max()*1.1,))\n",
    "\n",
    "cbar_ax = fig.add_axes([1.05, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(cm, cax=cbar_ax, label=\"Probability of damage\")\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.3, hspace=0.3,right=0.95)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each panel above describes the probability of being \"Damaged\", given the incident wind speed measure (horizontal axis) and rainfall measure (vertical axis). Note that the bounds on each axis vary for each variable.\n",
    "\n",
    "We now consider one of these panels for more deteailed investigation. The `PGWS` and `PIRR` variables give what we would intuitively expect to see from a predictor of damage - increasing probability for increasing values of the two predicor variables. \n",
    "\n",
    "This next section focuses on determining a discriminant function that we might be able to implement into an impact-forecasting workflow.\n",
    "\n",
    "We take a threshold of 50% probability of damage as our reference point. The figure below plots the contour that we're looking for. Note that it produces two contours on this figure, and we will take the longer of the two to derive the discriminant function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,1,figsize=(24,20),facecolor='white')\n",
    "ax = axes\n",
    "\n",
    "xx = np.linspace(0, 100, 1000)\n",
    "yy = np.linspace(0, 500, 1000)\n",
    "xp, yp = np.meshgrid(xx, yy)\n",
    "xvar = 'PGWS'\n",
    "yvar = 'PIRR'\n",
    "X = np.array([gdf[xvar].values, gdf[yvar].values]).T\n",
    "y = gdf['Damaged'].values\n",
    "clf = QDA()\n",
    "clf.fit(X, y)\n",
    "Z = clf.predict_proba(np.c_[xp.ravel(), yp.ravel()])\n",
    "Z = Z[:, 1].reshape(xp.shape)\n",
    "cm = ax.pcolormesh(xp, yp, Z, cmap='viridis', norm=colors.Normalize(0., 1))\n",
    "cs = ax.contour(xp, yp, Z, [0.5], linewidths=2., colors='k')\n",
    "cbar_ax = fig.add_axes([1.05, 0.15, 0.05, 0.7])\n",
    "\n",
    "fig.colorbar(cm, cax=cbar_ax, label=\"Probability of damage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_verts(cn):\n",
    "    contours = []\n",
    "    # for each contour line\n",
    "    for cc in cn.collections:\n",
    "        paths = []\n",
    "        # for each separate section of the contour line\n",
    "        for pp in cc.get_paths():\n",
    "            xy = []\n",
    "            # for each segment of that section\n",
    "            for vv in pp.iter_segments():\n",
    "                xy.append(vv[0])\n",
    "            paths.append(np.vstack(xy))\n",
    "        contours.append(paths)\n",
    "\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = get_contour_verts(cs)[0][1][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `cn` variable is a list of vertices of the 0.5 probability contour in the above plot. I have selected the second contour (by first inspecting the full set of returned vertices), and the last vertex is dropped, as it is repeated (which will cause problems with the curve fitting in the next step). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x, a, b, c):\n",
    "    value = (a/(x + b)) + c\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt, pcov = curve_fit(func, cn[:,0], cn[:,1], maxfev=100000)\n",
    "print(popt)\n",
    "print(pcov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,1,figsize=(12,10),facecolor='white')\n",
    "plt.plot(cn[:,0], func(cn[:,0], *popt))\n",
    "plt.xlabel(xvar)\n",
    "plt.ylabel(yvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,1,figsize=(12,10),facecolor='white')\n",
    "xx2 = np.linspace(0, 50, 1000)\n",
    "yy2 = np.linspace(0, 500, 1000)\n",
    "xp2, yp2 = np.meshgrid(xx2, yy2)\n",
    "\n",
    "Z2 = np.c_[yp2.ravel()] - func(np.c_[xp2.ravel()], *popt)\n",
    "Z2 = Z2.reshape(xp2.shape)\n",
    "plt.contour(xp2, yp2, Z2, [0], linewidths=2., colors='k')\n",
    "plt.contourf(xp2, yp2, Z2, levels=10, cmap='viridis',)\n",
    "plt.colorbar()\n",
    "plt.xlabel(xvar)\n",
    "plt.ylabel(yvar)\n",
    "plt.tight_layout()\n",
    "plt.savefig(pjoin(data_path, 'predictor.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmgthresh(pswg, pirr):\n",
    "    v = (popt[0]/(pswg + popt[1])) + popt[2] - pirr\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmg = dmgthresh(gdf[xvar].values, gdf[yvar].values)\n",
    "sns.distplot(dmg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['FcastDMG'] = dmg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfile = \"damage_forecast.shp\"\n",
    "gdf.to_file(pjoin(data_path, outputfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(gdf[['PIRR', 'P1RR', 'N1RR', 'P6RR', 'PTEA', 'PSWG', 'PSMW', 'NSWG', 'PGWS']],\n",
    "                 markers=\"+\", plot_kws={'alpha':0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['EICU_Degda'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
